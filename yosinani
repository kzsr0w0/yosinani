import MeCab
import pandas as pd
import chardet
import csv

# テキストファイルのエンコーディングを検出
def detect_encoding(file_path):
    with open(file_path, 'rb') as file:
        raw_data = file.read()
        result = chardet.detect(raw_data)
        return result['encoding']

# テキストファイルの内容を読み込む
def read_file(file_path, encoding):
    with open(file_path, 'r', encoding=encoding) as file:
        return file.read()

# 単語の出現回数をカウント
def count_words(text):
    word_count = {}
    mecabTagger = MeCab.Tagger()
    node = mecabTagger.parseToNode(text)
    while node:
        word = node.surface
        if word in word_count:
            word_count[word] += 1
        else:
            word_count[word] = 1
        node = node.next
    return word_count

# 結果をCSVに出力
def output_to_csv(count_dict, output_path):
    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Word', 'Count'])
        for word, count in count_dict.items():
            writer.writerow([word, count])

# ファイルパス
input_file_path = 'まとめ_1から13まで.txt'
output_file_path = 'output.csv'

# ファイルからテキストを読み込む
encoding = detect_encoding(input_file_path)
text = read_file(input_file_path, encoding)

# 単語の出現回数をカウント
word_count = count_words(text)

# 結果をCSVに出力
output_to_csv(word_count, output_file_path)